{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "* Need to work out pagination in queries, and how to recognize current data length such that only query new records "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install flipside"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flipside import Flipside\n",
    "from config import flipside_api_key, flipside_nft_holder_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdk = Flipside(flipside_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Checklist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "* [X] Curve Locks\n",
    "* [X] Curve Votes\n",
    "\n",
    "* [X] Gauge to LP map\n",
    "* [X] Curve Liquidity\n",
    "\n",
    "* [X] Convex Snapshot\n",
    "* [X] Votium Bounties\n",
    "\n",
    "* [X] StakeDAO Snapshot\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title = \"_may_12\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Save Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/app/data/source\"\n",
    "\n",
    "def get_cwd():\n",
    "    cwd_temp = os.getcwd()\n",
    "    temp_split = cwd_temp.split('/')\n",
    "    cwd = \"\"\n",
    "    for x in temp_split:\n",
    "        if x == 'experiments':\n",
    "            break\n",
    "        elif x == '':\n",
    "            pass\n",
    "        else:\n",
    "            cwd += \"/\"+x       \n",
    "    return cwd\n",
    "\n",
    "\n",
    "def print_metrics(query):\n",
    "    started_at = query.run_stats.started_at\n",
    "    ended_at = query.run_stats.ended_at\n",
    "    elapsed_seconds = query.run_stats.elapsed_seconds\n",
    "    record_count = query.run_stats.record_count\n",
    "    print(f\"This query took ${elapsed_seconds} seconds to run and returned {record_count} records from the database.\")\n",
    "\n",
    "def query_and_save(_query, _filename, _page_size = 5000):\n",
    "    # Initial Query\n",
    "    print(f\"___\\n{_filename}\")\n",
    "    print(f\"querying page: 1\")\n",
    "    query_result_set = sdk.query(_query, page_size = _page_size)\n",
    "    df_output = pd.json_normalize(query_result_set.records)\n",
    "  \n",
    "    # Metrics\n",
    "    print_metrics(query_result_set)\n",
    "    \n",
    "    # Handle Pagination\n",
    "    if len(query_result_set.records) >= _page_size:\n",
    "        i = 2\n",
    "        keep_going = True\n",
    "        while keep_going:\n",
    "            print(f\"querying page: {i}\")\n",
    "            extended_result_set = sdk.get_query_results(\n",
    "                query_result_set.query_id,\n",
    "                page_number=i,\n",
    "                page_size=_page_size\n",
    "            )\n",
    "            # Metrics\n",
    "            print_metrics(query_result_set)\n",
    "            \n",
    "            # Concat Dataframes\n",
    "            df_local = pd.json_normalize(extended_result_set.records)\n",
    "            df_output = pd.concat([df_output, df_local], ignore_index=True)\n",
    "            \n",
    "            # Check if continue\n",
    "            print(len(extended_result_set.records) < _page_size)\n",
    "            print(len(extended_result_set.records))\n",
    "            if len(extended_result_set.records) < _page_size:\n",
    "                keep_going = False\n",
    "            i += 1\n",
    "    # Save\n",
    "    cwd = get_cwd()\n",
    "    full_filename = cwd+ data_path + '/' + filename+'.csv'\n",
    "    df_output.to_csv(full_filename) \n",
    "    \n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curve Locker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_locker_address = '0x5f3b5DfEb7B28CDbD7FAba78963EE202a494e2A2'\n",
    "\n",
    "curve_locker_query = f\"\"\"SELECT \n",
    "  *,\n",
    "  WEEK(BLOCK_TIMESTAMP) as WEEK_NUMBER,\n",
    "  DAYOFWEEK(BLOCK_TIMESTAMP) as WEEK_DAY\n",
    "\n",
    "FROM ethereum.core.ez_decoded_event_logs\n",
    "WHERE CONTRACT_ADDRESS = lower('{curve_locker_address}')\n",
    "\"\"\"\n",
    "# AND BLOCK_TIMESTAMP <'2022-01-01 00:00:00.000'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___\n",
      "curve_locker\n",
      "querying page: 1\n",
      "This query took $203 seconds to run and returned 99332 records from the database.\n",
      "querying page: 2\n",
      "This query took $203 seconds to run and returned 99332 records from the database.\n",
      "False\n",
      "5000\n",
      "querying page: 3\n",
      "This query took $203 seconds to run and returned 99332 records from the database.\n",
      "False\n",
      "5000\n",
      "querying page: 4\n",
      "This query took $203 seconds to run and returned 99332 records from the database.\n",
      "False\n",
      "5000\n",
      "querying page: 5\n",
      "This query took $203 seconds to run and returned 99332 records from the database.\n",
      "False\n",
      "5000\n",
      "querying page: 6\n",
      "This query took $203 seconds to run and returned 99332 records from the database.\n",
      "False\n",
      "5000\n",
      "querying page: 7\n",
      "This query took $203 seconds to run and returned 99332 records from the database.\n",
      "False\n",
      "5000\n",
      "querying page: 8\n",
      "This query took $203 seconds to run and returned 99332 records from the database.\n",
      "False\n",
      "5000\n",
      "querying page: 9\n",
      "This query took $203 seconds to run and returned 99332 records from the database.\n",
      "False\n",
      "5000\n",
      "querying page: 10\n",
      "This query took $203 seconds to run and returned 99332 records from the database.\n",
      "False\n",
      "5000\n",
      "querying page: 11\n",
      "This query took $203 seconds to run and returned 99332 records from the database.\n",
      "False\n",
      "5000\n",
      "querying page: 12\n",
      "This query took $203 seconds to run and returned 99332 records from the database.\n",
      "False\n",
      "5000\n",
      "querying page: 13\n",
      "This query took $203 seconds to run and returned 99332 records from the database.\n",
      "False\n",
      "5000\n",
      "querying page: 14\n",
      "This query took $203 seconds to run and returned 99332 records from the database.\n",
      "False\n",
      "5000\n",
      "querying page: 15\n",
      "This query took $203 seconds to run and returned 99332 records from the database.\n",
      "False\n",
      "5000\n",
      "querying page: 16\n",
      "This query took $203 seconds to run and returned 99332 records from the database.\n",
      "False\n",
      "5000\n",
      "querying page: 17\n",
      "This query took $203 seconds to run and returned 99332 records from the database.\n",
      "False\n",
      "5000\n",
      "querying page: 18\n",
      "This query took $203 seconds to run and returned 99332 records from the database.\n",
      "False\n",
      "5000\n",
      "querying page: 19\n",
      "This query took $203 seconds to run and returned 99332 records from the database.\n",
      "False\n",
      "5000\n",
      "querying page: 20\n",
      "This query took $203 seconds to run and returned 99332 records from the database.\n",
      "True\n",
      "4332\n"
     ]
    }
   ],
   "source": [
    "filename = 'curve_locker'\n",
    "df_curve_locker = query_and_save(curve_locker_query, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curve Gauge Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_voter_address = '0x2F50D538606Fa9EDD2B11E2446BEb18C9D5846bB'\n",
    "\n",
    "curve_gauge_vote_query = f\"\"\"SELECT \n",
    "    SYMBOL, \n",
    "    NAME, \n",
    "    WEEK(BLOCK_TIMESTAMP) as WEEK_NUMBER,\n",
    "    DAYOFWEEK(BLOCK_TIMESTAMP) as WEEK_DAY,\n",
    "    DECODED_LOG,\n",
    "    TX_HASH,\n",
    "    BLOCK_TIMESTAMP\n",
    "\n",
    "FROM ethereum.core.ez_decoded_event_logs LOGS\n",
    " LEFT JOIN ethereum.core.dim_contracts CONTRACT\n",
    "   ON CONTRACT.address = lower(LOGS.DECODED_LOG:gauge_addr::string)\n",
    "WHERE CONTRACT_ADDRESS = lower('{curve_voter_address}')\n",
    "AND EVENT_NAME = 'VoteForGauge'\n",
    "ORDER BY BLOCK_TIMESTAMP ASC\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___\n",
      "curve_gauge_votes\n",
      "querying page: 1\n",
      "This query took $56 seconds to run and returned 24460 records from the database.\n",
      "querying page: 2\n",
      "This query took $56 seconds to run and returned 24460 records from the database.\n",
      "False\n",
      "10000\n",
      "querying page: 3\n",
      "This query took $56 seconds to run and returned 24460 records from the database.\n",
      "True\n",
      "4460\n"
     ]
    }
   ],
   "source": [
    "filename = 'curve_gauge_votes'\n",
    "df_curve_locker = query_and_save(curve_gauge_vote_query, filename, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snapshot Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "convex_snapshot_votes_query = f\"\"\"\n",
    "SELECT \n",
    "    PROPOSAL_ID, \n",
    "    PROPOSAL_START_TIME, \n",
    "    PROPOSAL_END_TIME, \n",
    "    PROPOSAL_TITLE, \n",
    "    PROPOSAL_AUTHOR,\n",
    "    VOTE_OPTION,\n",
    "    VOTING_POWER,\n",
    "    VOTE_TIMESTAMP,\n",
    "    QUORUM,\n",
    "    CHOICES,\n",
    "    VOTING_PERIOD,\n",
    "    NETWORK,\n",
    "    SPACE_ID,\n",
    "    VOTER,\n",
    "    ADDRESS_NAME,\n",
    "    LABEL_TYPE, \n",
    "    LABEL_SUBTYPE,\n",
    "    LABEL\n",
    "FROM ethereum.core.ez_snapshot SNAPSHOT\n",
    " LEFT JOIN ethereum.core.dim_labels LABELS\n",
    "   ON SNAPSHOT.VOTER = LABELS.ADDRESS\n",
    "WHERE SPACE_ID = 'cvx.eth' \n",
    "AND PROPOSAL_TITLE LIKE 'Gauge Weight%'\n",
    "AND VOTE_TIMESTAMP > '2022-12-20 00:00:00.000'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stakedao_snapshot_votes_query = f\"\"\"\n",
    "SELECT \n",
    "    PROPOSAL_ID, \n",
    "    PROPOSAL_START_TIME, \n",
    "    PROPOSAL_END_TIME, \n",
    "    PROPOSAL_TITLE, \n",
    "    PROPOSAL_AUTHOR,\n",
    "    VOTE_OPTION,\n",
    "    VOTING_POWER,\n",
    "    VOTE_TIMESTAMP,\n",
    "    QUORUM,\n",
    "    CHOICES,\n",
    "    VOTING_PERIOD,\n",
    "    NETWORK,\n",
    "    SPACE_ID,\n",
    "    VOTER,\n",
    "    ADDRESS_NAME,\n",
    "    LABEL_TYPE, \n",
    "    LABEL_SUBTYPE,\n",
    "    LABEL\n",
    "FROM ethereum.core.ez_snapshot SNAPSHOT\n",
    " LEFT JOIN ethereum.core.dim_labels LABELS\n",
    "   ON SNAPSHOT.VOTER = LABELS.ADDRESS\n",
    "WHERE SPACE_ID = 'sdcrv.eth' \n",
    "AND PROPOSAL_TITLE LIKE 'Gauge vote - CRV%'\n",
    "AND VOTE_TIMESTAMP > '2022-12-20 00:00:00.000'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___\n",
      "convex_snapshot_votes\n",
      "querying page: 1\n",
      "This query took $77 seconds to run and returned 15746 records from the database.\n",
      "querying page: 2\n",
      "This query took $77 seconds to run and returned 15746 records from the database.\n",
      "False\n",
      "1500\n",
      "querying page: 3\n",
      "This query took $77 seconds to run and returned 15746 records from the database.\n",
      "False\n",
      "1500\n",
      "querying page: 4\n",
      "This query took $77 seconds to run and returned 15746 records from the database.\n",
      "False\n",
      "1500\n",
      "querying page: 5\n",
      "This query took $77 seconds to run and returned 15746 records from the database.\n",
      "False\n",
      "1500\n",
      "querying page: 6\n",
      "This query took $77 seconds to run and returned 15746 records from the database.\n",
      "False\n",
      "1500\n",
      "querying page: 7\n",
      "This query took $77 seconds to run and returned 15746 records from the database.\n",
      "False\n",
      "1500\n",
      "querying page: 8\n",
      "This query took $77 seconds to run and returned 15746 records from the database.\n",
      "False\n",
      "1500\n",
      "querying page: 9\n",
      "This query took $77 seconds to run and returned 15746 records from the database.\n",
      "False\n",
      "1500\n",
      "querying page: 10\n",
      "This query took $77 seconds to run and returned 15746 records from the database.\n",
      "False\n",
      "1500\n",
      "querying page: 11\n",
      "This query took $77 seconds to run and returned 15746 records from the database.\n",
      "True\n",
      "746\n"
     ]
    }
   ],
   "source": [
    "filename = 'convex_snapshot_votes'\n",
    "df_convex_snapshot_votes = query_and_save(convex_snapshot_votes_query, filename, 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___\n",
      "stakedao_snapshot\n",
      "querying page: 1\n",
      "This query took $11 seconds to run and returned 181 records from the database.\n"
     ]
    }
   ],
   "source": [
    "filename = 'stakedao_snapshot'\n",
    "df_stakdao_snapshot_votes = query_and_save(stakedao_snapshot_votes_query, filename, 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_curve_locker' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/meir/Dev/curve_governance_flask/load_data_initial.ipynb Cell 25\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/meir/Dev/curve_governance_flask/load_data_initial.ipynb#Y101sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_curve_locker\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_curve_locker' is not defined"
     ]
    }
   ],
   "source": [
    "df_convex_snapshot_votes.vote_timestamp.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference: Gauge to LP map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_voter_address = '0x2F50D538606Fa9EDD2B11E2446BEb18C9D5846bB'\n",
    "\n",
    "gauge_to_lp_map_query = \"\"\"\n",
    "with v2_deployer as (\n",
    "  SELECT\n",
    "    BLOCK_TIMESTAMP as block_timestamp,\n",
    "    DECODED_LOG:gauge::string as gauge_addr,\n",
    "    DECODED_LOG:pool::string as pool_addr,\n",
    "    DECODED_LOG:token::string as token_addr,\n",
    "    'v2' as type\n",
    "  \n",
    "  \n",
    "  FROM ethereum.core.ez_decoded_event_logs\n",
    "  WHERE CONTRACT_ADDRESS = lower('0xF18056Bbd320E96A48e3Fbf8bC061322531aac99') -- v2 deployer\n",
    "  AND EVENT_NAME = 'LiquidityGaugeDeployed'\n",
    "\n",
    "),\n",
    "\n",
    "factory_deployer as (\n",
    "  SELECT \n",
    "    BLOCK_TIMESTAMP as block_timestamp,\n",
    "    DECODED_LOG:gauge::string as gauge_addr,\n",
    "    DECODED_LOG:pool::string as pool_addr,\n",
    "    '' as token_addr,\n",
    "    'factory' as type\n",
    "\n",
    "  FROM ethereum.core.ez_decoded_event_logs as logs\n",
    "\n",
    "  WHERE logs.CONTRACT_ADDRESS = lower('0xB9fC157394Af804a3578134A6585C0dc9cc990d4')  -- factory\n",
    "  AND logs.EVENT_NAME = 'LiquidityGaugeDeployed'\n",
    "),\n",
    "\n",
    "\n",
    "combo as (\n",
    "  SELECT gauge_addr, pool_addr, token_addr, type, block_timestamp FROM v2_deployer\n",
    "  UNION\n",
    "  SELECT gauge_addr, pool_addr, token_addr, type, block_timestamp  FROM factory_deployer\n",
    ")\n",
    "\n",
    "SELECT \n",
    "  combo.gauge_addr as GAUGE_ADDR, \n",
    "  combo.pool_addr as POOL_ADDR, \n",
    "  combo.token_addr as TOKEN_ADDR, \n",
    "  combo.type as TYPE, \n",
    "  combo.block_timestamp as BLOCK_TIMESTAMP,\n",
    "  contracts.NAME as GAUGE_NAME,\n",
    "  contracts.SYMBOL as GAUGE_SYMBOL,\n",
    "  pool_contracts.NAME as POOL_NAME,\n",
    "  pool_contracts.SYMBOL as POOL_SYMBOL,\n",
    "  token_contracts.NAME as TOKEN_NAME,\n",
    "  token_contracts.SYMBOL as TOKEN_SYMBOL\n",
    "FROM combo\n",
    "LEFT JOIN ethereum.core.dim_contracts as contracts\n",
    "  ON combo.gauge_addr = contracts.ADDRESS\n",
    "LEFT JOIN ethereum.core.dim_contracts as pool_contracts\n",
    "  ON combo.pool_addr = pool_contracts.ADDRESS\n",
    "LEFT JOIN ethereum.core.dim_contracts as token_contracts\n",
    "  ON combo.token_addr = token_contracts.ADDRESS\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___\n",
      "gauge_to_lp_map\n",
      "querying page: 1\n",
      "This query took $19 seconds to run and returned 272 records from the database.\n"
     ]
    }
   ],
   "source": [
    "filename = 'gauge_to_lp_map'\n",
    "df_curve_locker = query_and_save(gauge_to_lp_map_query, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Votium Bounties "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "votium_bounty_query = f\"\"\"SELECT \n",
    "  -- *\n",
    "  EVENT_NAME,\n",
    "  -- BLOCK_TIMESTAMP,\n",
    "  TX_HASH,\n",
    "  DECODED_LOG:_choiceIndex::int as choice_index,\n",
    "  DECODED_LOG:_amount::int / pow(10,18) as amount,\n",
    "  DECODED_LOG:_proposal::string as proposal_id,\n",
    "  DECODED_LOG:_token::string as bounty_token_address,\n",
    "  ORIGIN_FROM_ADDRESS,\n",
    "  BLOCK_TIMESTAMP as block_timestamp,\n",
    "  PRICE as price,\n",
    "  price * amount as bounty_value,\n",
    "  contracts.NAME as token_name,\n",
    "  contracts.SYMBOL as token_symbol\n",
    "  -- snap.CHOICES as CHOICES\n",
    "FROM ethereum.core.ez_decoded_event_logs as logs\n",
    "LEFT JOIN ethereum.core.fact_hourly_token_prices as prices\n",
    "ON logs.DECODED_LOG:_token = prices.token_address\n",
    "AND time_slice(logs.BLOCK_TIMESTAMP::timestamp_ntz, 1, 'HOUR') = prices.HOUR\n",
    "LEFT JOIN ethereum.core.dim_contracts as contracts\n",
    "ON logs.DECODED_LOG:_token = contracts.ADDRESS\n",
    "-- time_slice(logs.BLOCK_TIMESTAMP::timestamp_ntz, 1, 'HOUR')\n",
    "\n",
    "-- LEFT JOIN  ethereum.core.ez_snapshot as snap\n",
    "-- on lower(logs.DECODED_LOG:_proposal) = lower(snap.PROPOSAL_ID)\n",
    "WHERE CONTRACT_ADDRESS= lower('0x19bbc3463dd8d07f55438014b021fb457ebd4595')\n",
    "\n",
    "AND EVENT_NAME = 'Bribed'\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___\n",
      "votium_bounty_for_round\n",
      "querying page: 1\n",
      "This query took $15 seconds to run and returned 1726 records from the database.\n"
     ]
    }
   ],
   "source": [
    "filename = 'votium_bounty_for_round'\n",
    "df_curve_locker = query_and_save(votium_bounty_query, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curve Liquidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QueryRunExecutionError: QUERY_RUN_EXECUTION_ERROR: an error has occured while executing your query. errorName=OperationFailedError, errorMessage=SQL compilation error: error line 95 at position 74\n",
    "invalid identifier 'PRICES.TOKEN_SYMBOL', errorData={\n",
    "'code': '000904',\n",
    "'data': {'age': 0, 'pos': -1, 'line': -1, \n",
    "'type': 'COMPILATION', \n",
    "'queryId': '01aea26f-0403-b9d3-3d4f-83014f15269b', \n",
    "'sqlState': '42000', \n",
    "'errorCode': '000904', 'internalError': False}, \n",
    "'name': 'OperationFailedError', 'message': \"SQL compilation error: error line 95 at position 74\n",
    "invalid identifier 'PRICES.TOKEN_SYMBOL'\", \n",
    "'sqlState': '42000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2023-03-01 00:00:00.000'\n",
    "curve_liquidity_query = f\"\"\"\n",
    "with curve_swaps as (\n",
    "SELECT\n",
    "*\n",
    "FROM ethereum.core.ez_dex_swaps\n",
    "WHERE PLATFORM = 'curve' \n",
    "),\n",
    "\n",
    "tokens_out as (\n",
    "SELECT \n",
    "DISTINCT TOKEN_OUT as token,\n",
    "CONTRACT_ADDRESS as pool_address,\n",
    "POOL_NAME as pool_name,\n",
    "SYMBOL_OUT as symbol\n",
    "FROM curve_swaps\n",
    "GROUP BY TOKEN_OUT, SYMBOL_OUT, CONTRACT_ADDRESS, POOL_NAME\n",
    "),\n",
    "\n",
    "tokens_in as (\n",
    "SELECT \n",
    "DISTINCT TOKEN_IN as token,\n",
    "CONTRACT_ADDRESS as pool_address,\n",
    "POOL_NAME as pool_name,\n",
    "\n",
    "SYMBOL_IN  as symbol\n",
    "FROM curve_swaps\n",
    "-- GROUP BY TOKEN_IN\n",
    "),\n",
    "\n",
    "pools as (\n",
    "SELECT\n",
    "DISTINCT CONTRACT_ADDRESS as pool_address,\n",
    "POOL_NAME as pool_name,\n",
    "'ETH' as symbol,\n",
    "'' as token\n",
    "FROM curve_swaps\n",
    "-- GROUP BY CONTRACT_ADDRESS\n",
    "\n",
    "),\n",
    "\n",
    "tokens as (\n",
    "select \n",
    "*\n",
    "FROM tokens_out\n",
    "UNION all\n",
    "select \n",
    "*\n",
    "FROM tokens_in\n",
    "UNION all\n",
    "select \n",
    "token, pool_address, pool_name, symbol\n",
    "FROM pools\n",
    "),\n",
    "\n",
    "all_tokens as (\n",
    "select \n",
    "* \n",
    "from tokens\n",
    "group by token, symbol, pool_address, pool_name\n",
    "),\n",
    "\n",
    "\n",
    "-- COMBINE TOKENS WITH DATES\n",
    "dates as (\n",
    "select \n",
    "date_day \n",
    "from ethereum.core.dim_dates \n",
    "where date_day between '{start_date}' and current_date()\n",
    "),\n",
    "\n",
    "dates_x_tokens as (\n",
    "select \n",
    "date_day,\n",
    "symbol,\n",
    "token,\n",
    "pool_address,\n",
    "pool_name\n",
    "\n",
    "from dates\n",
    "cross join all_tokens\n",
    "ORDER BY date_day DESC\n",
    "),\n",
    "\n",
    "\n",
    "dates_x_tokens_x_price as (\n",
    "select \n",
    "dates_x_tokens.date_day,\n",
    "dates_x_tokens.symbol,\n",
    "dates_x_tokens.token,\n",
    "pool_address,\n",
    "pool_name,\n",
    "AVG(prices.PRICE) as daily_price\n",
    "FROM dates_x_tokens\n",
    "LEFT JOIN ethereum.core.fact_hourly_token_prices as prices\n",
    "ON (dates_x_tokens.token = prices.TOKEN_ADDRESS \n",
    "  OR dates_x_tokens.token = prices.SYMBOL\n",
    "  )\n",
    "AND dates_x_tokens.date_day = prices.hour::date\n",
    "GROUP BY (\n",
    "  dates_x_tokens.date_day,\n",
    "  dates_x_tokens.symbol,\n",
    "  dates_x_tokens.token,\n",
    "  dates_x_tokens.pool_address,\n",
    "  dates_x_tokens.pool_name\n",
    "  )\n",
    "ORDER BY date_day DESC\n",
    "\n",
    "),\n",
    "\n",
    "\n",
    "balances as (\n",
    "select\n",
    "\n",
    "dates.date_day,\n",
    "dates.pool_address,\n",
    "dates.pool_name, \n",
    "dates.token,\n",
    "dates.symbol,\n",
    "sum(deltas.BAL_DELTA) as balance,\n",
    "(balance * dates.daily_price) as balance_usd \n",
    "\n",
    "from dates_x_tokens_x_price as dates\n",
    "left join ethereum.core.ez_balance_deltas as deltas\n",
    "ON deltas.BLOCK_TIMESTAMP::date <= dates.date_day\n",
    "AND deltas.USER_ADDRESS = dates.pool_address\n",
    "AND (deltas.CONTRACT_ADDRESS = dates.token\n",
    "OR dates.symbol = deltas.SYMBOL)\n",
    "GROUP BY (\n",
    "  dates.date_day,\n",
    "  dates.pool_address,\n",
    "  dates.pool_name, \n",
    "  dates.token,\n",
    "  dates.symbol,\n",
    "  dates.daily_price\n",
    "  )\n",
    "ORDER BY date_day DESC\n",
    "\n",
    ") \n",
    "\n",
    "\n",
    "SELECT\n",
    "  date_day, \n",
    "  pool_name,\n",
    "  sum(balance) as current_bal,\n",
    "  sum(balance_usd) as current_bal_usd,\n",
    "  LISTAGG(symbol, ', ') as tradeable_assets,\n",
    "  pool_address\n",
    "FROM balances\n",
    "GROUP BY date_day, pool_address, pool_name\n",
    "ORDER BY date_day DESC\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___\n",
      "liquidity_general\n",
      "querying page: 1\n"
     ]
    }
   ],
   "source": [
    "filename = 'liquidity_general'\n",
    "df_liquidity_general = query_and_save(curve_liquidity_query, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cadcad-edu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
